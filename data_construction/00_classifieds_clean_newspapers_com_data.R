### finalize newspapers.com data ###

library(tidyverse)
library(lubridate)
library(data.table)
library(readxl)
library(glue)

## change to directory where archive was extracted
data_dir <- "~/craigslist-replication-code-and-data/data"

## initial run
load(glue("{data_dir}/Newspapers.com/npcom_classified_pages_with_totals.RData"))
npcom_pages[, date := ymd(date)]

## re-scrape of unusual looking entries
auto_fixes <- fread(glue("{data_dir}/Newspapers.com/classified_pages_auto_check.csv")) %>%
    .[!is.na(date), .(link, date = ymd(date), auto_corrected_pages = cl_pages)]

## manual checks of long strings of zeros using table of contents
manual_fix_1 <- read_excel(glue("{data_dir}/Newspapers.com/Newspapers manual check PART 1.xlsx")) %>%
    setDT %>%
    .[, .(link,
          date = ymd(date),
          manual_corrected_pages = parse_number(cl_pages_excluding))]
manual_fix_2 <- read_excel(glue("{data_dir}/Newspapers.com/Newspapers manual check PART 2.xlsx")) %>%
    setDT %>%
        .[, .(link,
              date = ymd(date),
              manual_corrected_pages = parse_number(cl_pages_excluding, na = c("na", "", "NA")))]

manual_fixes <- rbind(manual_fix_1, manual_fix_2) %>%
    .[, .(manual_corrected_pages = if_else(all(is.na(manual_corrected_pages)), as.numeric(NA), max(manual_corrected_pages))), 
      by = .(link, date)]


npcom_pages <- auto_fixes[npcom_pages, on = .(link, date)]
npcom_pages <- manual_fixes[npcom_pages, on = .(link, date)]

# drop yorkdailyrecordPA before 2004. replace with saturday values, generated by classified_page_cleanup.R
npcom_pages <- npcom_pages[!(np_name == "yorkdailyrecordPA" & date < ymd("2004-06-01"))]
york_pages <- fread(glue("{data_dir}/Newspapers.com/classified_pages_yorkdailyrecord.csv"))
york_pages[, date := ymd(date)]
npcom_pages <- rbind(npcom_pages, york_pages, fill = T)

# manual fixes of 1's for large papers. NA's here are true missings
manual_fix_3 <- fread(glue("{data_dir}/Newspapers.com/newspapers_com_issues_for_manual_check_1s.csv")) %>%
    .[, .(link,
          date = mdy(date),
          manual_corrected_pages_1 = cl_pages_excluding,
          found_in_check1 = T)]

npcom_pages <- manual_fix_3[npcom_pages, on = .(link, date)]


npcom_pages[, cl_pages_corrected := cl_pages_excluding]
npcom_pages[!is.na(manual_corrected_pages) & manual_corrected_pages > 0,
    cl_pages_corrected := manual_corrected_pages]
npcom_pages[!is.na(auto_corrected_pages) & auto_corrected_pages > 0,
    cl_pages_corrected := auto_corrected_pages]
npcom_pages[!is.na(found_in_check1), cl_pages_corrected := manual_corrected_pages_1]

paper_summary <- npcom_pages[, .(m = mean(cl_pages_corrected, na.rm=T),
                med = median(cl_pages_corrected, na.rm=T),
                sd = sd(cl_pages_corrected, na.rm=T),
                nz = sum(cl_pages_corrected == 0),
                nmiss = sum(is.na(cl_pages_corrected))), by = .(np_name)]

paper_summary[nz > 5][order(med, decreasing = T)]

# treat zeros as missings for large papers
npcom_pages[, median_pages := median(cl_pages_corrected, na.rm = T), by = .(np_name)]
npcom_pages[cl_pages_corrected == 0 & median_pages >= 10, cl_pages_corrected := NA]

# windsorize at 95th percentile by paper
npcom_pages[, cl_pages_corrected := pmin(cl_pages_corrected, ceiling(quantile(cl_pages_corrected, 0.95, na.rm = T))), by = .(np_name)]
npcom_pages[, cl_pages_corrected := pmax(cl_pages_corrected, floor(quantile(cl_pages_corrected, 0.05, na.rm = T))), by = .(np_name)]

# harmonize a few extra newspaper names
npcom_pages[np_name == "tinleyparksouthtownstarIL", np_name := "tinleyparkdailysouthtownIL"]
npcom_pages[np_name == "sanbernardinocountysunCA", np_name := "sanbernardinosunCA"]
npcom_pages[np_name == "pottsvillerepublicanPA", np_name := "pottsvillerepublicanandeveningheraldPA"]
npcom_pages[np_name == "oklahomacitydailyoklahomanOK", np_name := "oklahomacityoklahomanOK"]
npcom_pages[np_name == "mcalesternewscapitalanddemocratOK", np_name := "mcalesternewscapitalOK"]


save(npcom_pages, file = glue("{data_dir}/Newspapers.com/npcom_classified_pages_with_totals_corrected.RData"))
